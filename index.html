<!DOCTYPE html>
<html lang='en'>

<head>
    <base href=".">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Multimodal Representation and Retrieval Workshop at ICCV 2025">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference, Workshop, Multimodal, Representation, Retrieval, ICCV">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://mrr-workshop.github.io/">
    <meta property="og:title" content="Multimodal Representation and Retrieval [MRR 2025]">
    <meta property="og:description" content="A workshop on multimodal representation and retrieval at ICCV 2025, focusing on multimodal data in applications like e-commerce, social media, and short videos.">
    <meta property="og:image" content="https://mrr-workshop.github.io/assets/pexels-lastly-412681-half.jpg">
    
    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://mrr-workshop.github.io/">
    <meta property="twitter:title" content="Multimodal Representation and Retrieval [MRR 2025]">
    <meta property="twitter:description" content="A workshop on multimodal representation and retrieval at ICCV 2025, focusing on multimodal data in applications like e-commerce, social media, and short videos.">
    <meta property="twitter:image" content="https://mrr-workshop.github.io/assets/pexels-lastly-412681-half.jpg">
    <style>
        .profile-image {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            object-fit: cover;
            margin-right: 10px;
            vertical-align: middle;
        }
        .profile-link {
            display: flex;
            align-items: center;
            text-decoration: none;
            color: black;
        }
        @media (max-width: 600px) {
            .profile-link {
                flex-direction: column;
                align-items: flex-start;
            }
            .profile-image {
                margin-bottom: 10px;
            }
        }
    </style>
    <style>
        .navigation {
            width: 100%;
            text-align: center;
            border-collapse: collapse;
        }
        .navigation td {
            padding: 10px 20px; /* Adjust padding as needed */
        }
        .navigation a {
            text-decoration: none;
            color: black;
            font-size: 16px;
            font-weight: bold;
        }
        .navigation a:hover {
            color: goldenrod;
        }
    </style>
    <title>Multimodal Representation and Retrieval [MRR 2025]</title>
</head>


<body>

    <a id="home"><div class="banner">
        <img src="assets/pexels-lastly-412681-half.jpg" alt="Conference Template Banner" width="1000px">
        <div class="top-center">
            <span class="title1">Multimodal Representation and Retrieval</span><br />
        </div>
	<div class="top-left">
	  <span class="title2"></span> <span class="year">MRR 2025</span>
	</div>
        <div class="bottom-right">
            October 19/20, 2025 @ ICCV <br> Honolulu, Hawai'i
        </div>
    </div></a>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a class="current" title="Conference Home Page" href="index.html#">Home</a>
            </td>
            <td class="navigation">
                <a title="Register for the Conference" href="https://iccv.thecvf.com/Conferences/2025/">Registration (ICCV 2025)</a>
            </td>
            <td class="navigation">
                <a title="Past Events" href="index.html#past_events">Past Events</a> 
            </td>
            <td class="navigation">
                <a title="Organizers" href="index.html#organizers">Organizers</a>
            </td>
        </tr>
    </table>

    <h2>Abstract</h2>
    <p style="margin: 0; padding: 0;">
Multimodal data is available in many applications like e-commerce production listings, social media posts and short videos. However, existing algorithms dealing with those types of data still focus on uni-modal representation learning by vision-language alignment and cross-modal retrieval. In this workshop, we target to bring a new retrieval problem where both queries and documents are multimodal. With the popularity of vision language modeling, large language models (LLMs), retrieval augmented generation (RAG), and multimodal LLM, we see a lot of new opportunities for multimodal representation and retrieval tasks. This event will be a comprehensive workshop focusing on the subject of multimodal representation and retrieval.
    </p>


    <a id="cfp"><h2>Call for Papers</h2></a>
    <br />
    <p style="margin: 0; padding: 0;">
    Our objective with this workshop is to capture the interest of researchers in the emerging field of multimodal retrieval and representation learning. As users increasingly use LLM based agents to interact with the world, the tools needed to retrieve relevant information will need to evolve to serve agents as well as human users. We anticipate that the workshop will serve as a catalyst for establishing a dedicated community focused on this topic. By highlighting the novelty and significance of the problem, we aim to attract researchers who are eager to explore and contribute to this field. We invite original research & industrial application papers that present research on learning multimodal representations and building multimodal retrieval systems.
    </p>

    <section id="submission-guidelines">
        <h3>Submission Guidelines</h3>
        <p style="margin: 0; padding: 0;">Submissions of papers must be in English, in PDF format, and at most 8 pages (including figures, tables, proofs, appendixes, acknowledgments, and any content except references) in length, with unrestricted space for references, in the ICCV style. Please download the <a href="https://media.eventhosts.cc/Conferences/ICCV2025/ICCV2025-Author-Kit-Feb.zip">ICCV 2025 Author Kit</a> for detailed formatting instructions.</p>
        <br/>
        <p style="margin: 0; padding: 0;">Papers that are not properly anonymized, or do not use the template, or have less than four pages or more than eight pages (excluding references) will be rejected without review. We expect at least one author from each submission to be available as a reviewer.</p>
        <br/>
        <p style="margin: 0; padding: 0;">Submissions should be submitted electronically:</p>
        <br/>
        <p><a href="https://openreview.net/group?id=thecvf.com/ICCV/2025/Workshop/MRR">Submit via OpenReview</a></p>
        <br/>
        <p style="margin: 0; padding: 0;">The accepted papers will appear in ICCV proceedings by default unless the authors notify the organizers (email: xlzhu AT amazon.com) separately before Jun 26 (11:59 pm, PST).</p>
    
        <h3>Important dates for submissions to MRR 2025</h3>
        <ul class="custom-bullets">
            <li>Workshop paper submission due date: June 3, 2025 (11:59 pm, AoE)</li>
            <li>Workshop paper acceptance notification: June 25, 2025</li>
            <li>Workshop day: October 19/20, 2025</li>
        </ul>
        
        <section id="topics">
            <h3>Topics includes but not limited to</h3>
            <ul class="custom-bullets">
                <li><strong>Multimodal representation learning and retrieval, such as</strong>
                    <ul class="custom-sub-bullets">
                        <li>Multimodal embeddings learning and fusion</li>
                        <li>Multimodal representation for reasoning</li>
                        <li>Learning with noisy labels</li>
                        <li>Multimodal query representation</li>
                        <li>Multimodal query understanding</li>
                        <li>Multimodal query suggestion</li>
                        <li>Ranking algorithms for multimodal retrieval</li>
                    </ul>
                </li>

                <li><strong>Dataset, such as</strong>
                    <ul class="custom-sub-bullets">
                        <li>New dataset for multimodal representation/reasoning/retrieval</li>
                        <li>Ways to synthesize data</li>
                    </ul>
                </li>

                <li><strong>Applications of Multimodal Retrieval, such as</strong>
                    <ul class="custom-sub-bullets">
                        <li>Multimodal retrieval in RAG</li>
                        <li>Multimodal retrieval in Agentic AI</li>
                        <li>Multimodal retrieval in search engine</li>
                        <li>Multimodal retrieval in recommendation system</li>
                        <li>Multimodal retrieval in Ads</li>
                        <li>Multimodal retrieval in Chatbot</li>
                        <li>Multimodal query suggestion</li>
                        <li>Multimodal retrieval in Robotics</li>
                    </ul>
                </li>
            </ul>
        </section>
        
    <a id="past_events"><h2>Past Events</h2></a>
    <ul class="custom-bullets">
        <li><a href="2024/">MRR 2024 @ SIGIR</a> - July 18, 2024, Washington DC</li>
    </ul>

 <a id="organizers"><h2>Organizers</h2></a>
    <ul>
        <li>
            <a class="profile-link" href="https://www.linkedin.com/in/xinliang-zhu-6b589942/">
                <img class="profile-image" src="./assets/Organizer/xinliang.jpg" alt="Xinliang Zhu"> Xinliang Zhu, Amazon
            </a>
        </li>
        <li>
            <a class="profile-link" href="https://www.linkedin.com/in/arnabdhua/">
                <img class="profile-image" src="./assets/Organizer/arnab.jpeg" alt="Arnab Dhua"> Arnab Dhua, Amazon
            </a>
        </li>
        <li>
            <a class="profile-link" href="https://people.ucas.edu.cn/~shengshengqian?language=en">
                <img class="profile-image" src="./assets/Organizer/shengsheng.png" alt="Shengsheng Qian"> Shengsheng Qian, Associate Professor, Chinese Academy of Sciences 
            </a>
        </li>
        <li>
            <a class="profile-link" href="https://eric-xw.github.io/">
                <img class="profile-image" src="./assets/Organizer/xin3.jpeg" alt="Xin (Eric) Wang"> Xin (Eric) Wang, Assistant Professor, University of California, Santa Cruz
            </a>
        </li>
        <li>
            <a class="profile-link" href="https://www.grasp.upenn.edu/people/rene-vidal/">
                <img class="profile-image" src="./assets/Organizer/rvidal16.png" alt="Rene Vidal"> Rene Vidal, Rachleff University Professor, University of Pennsylvania
            </a>
        </li>
        <li>
            <a class="profile-link" href="https://www.linkedin.com/in/de3ug/">
                <img class="profile-image" src="./assets/Organizer/doug.jpeg" alt="Douglas Gray"> Douglas Gray, Amazon
            </a>
        </li>
    </ul>

    <section id="contact">
      <h2>Contact</h2>
      <p>
        For any questions, please email
        <a href="mailto:mrr-2025-iccv@googlegroups.com">
          mrr-2025-iccv@googlegroups.com
        </a>.
      </p>
    </section>
    
    <footer>
        &copy; MRR Workshop Organizers 2025
    </footer>
</body>
</html>
